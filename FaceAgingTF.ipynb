{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceAgingTF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cseas/face-vae/blob/master/FaceAgingTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ORfKZeo8xq",
        "colab_type": "code",
        "outputId": "034abedb-7411-42a7-d129-42fef6fe5683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVwA2wfQnamS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/cseas/face-vae/master/dataloader.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZoyQnWooHMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/cseas/face-vae/master/misc.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYI5o3FVoZA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/cseas/face-vae/master/models.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxylPEkPonI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/cseas/face-vae/master/makeLabel.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne69TAS-pJlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf '/content/gdrive/My Drive/datasets/UTKFace.tar.gz' -C ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lu0k-bLkaPG",
        "colab_type": "code",
        "outputId": "af37fb38-54ac-4b78-be07-1c937fc332b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from dataloader import *\n",
        "from misc import *\n",
        "from models import *\n",
        "import pickle\n",
        "from makeLabel import *\n",
        "import os\n",
        "\n",
        "## boolean variable indicating whether cuda is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "makeDir()\n",
        "moveFiles()\n",
        "\n",
        "\n",
        "dataloader = loadImgs()\n",
        "\n",
        "## build model and use cuda if available\n",
        "if use_cuda:\n",
        "    netE = Encoder().cuda()\n",
        "    netD_img = Dimg().cuda()\n",
        "    netD_z  = Dz().cuda()\n",
        "    netG = Generator().cuda()\n",
        "else:\n",
        "    netE = Encoder()\n",
        "    netD_img = Dimg()\n",
        "    netD_z  = Dz()\n",
        "    netG = Generator()\n",
        "\n",
        "## apply weight initialization\n",
        "netE.apply(weights_init)\n",
        "netD_img.apply(weights_init)\n",
        "netD_z.apply(weights_init)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "## build optimizer for each networks\n",
        "optimizerE = optim.Adam(netE.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "optimizerD_z = optim.Adam(netD_z.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "optimizerD_img = optim.Adam(netD_img.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "\n",
        "## build criterions to calculate loss, and use cuda if available\n",
        "if use_cuda:\n",
        "    BCE = nn.BCELoss().cuda()\n",
        "    L1  = nn.L1Loss().cuda()\n",
        "    CE = nn.CrossEntropyLoss().cuda()\n",
        "    MSE = nn.MSELoss().cuda()\n",
        "else:\n",
        "    BCE = nn.BCELoss()\n",
        "    L1  = nn.L1Loss()\n",
        "    CE = nn.CrossEntropyLoss()\n",
        "    MSE = nn.MSELoss()\n",
        "\n",
        "## fixed variables to regress / progress age\n",
        "fixed_l = -torch.ones(80*10).view(80,10)\n",
        "for i,l in enumerate(fixed_l):\n",
        "    l[i//8] = 1\n",
        "\n",
        "fixed_l_v = Variable(fixed_l)\n",
        "\n",
        "if use_cuda:\n",
        "    fixed_l_v = fixed_l_v.cuda()\n",
        "\n",
        "\n",
        "outf='./result_tv_gender'\n",
        "\n",
        "if os.path.exists(outf):\n",
        "    os.mkdir(outf)\n",
        "\n",
        "niter=50\n",
        "\n",
        "for epoch in range(niter):\n",
        "    for i,(img_data,img_label) in enumerate(dataloader):\n",
        "\n",
        "        # make image variable and class variable\n",
        "\n",
        "        img_data_v = Variable(img_data)\n",
        "        img_age = img_label/2\n",
        "        img_gender = img_label%2*2-1\n",
        "\n",
        "        img_age_v = Variable(img_age).view(-1,1)\n",
        "        img_gender_v = Variable(img_gender.float())\n",
        "\n",
        "        if epoch == 0 and i == 0:\n",
        "            fixed_noise = img_data[:8].repeat(10,1,1,1)\n",
        "            fixed_g = img_gender[:8].view(-1,1).repeat(10,1)\n",
        "\n",
        "\n",
        "            fixed_img_v = Variable(fixed_noise)\n",
        "            fixed_g_v = Variable(fixed_g)\n",
        "\n",
        "            pickle.dump(fixed_noise,open(\"fixed_noise.p\",\"wb\"))\n",
        "\n",
        "            if use_cuda:\n",
        "                fixed_img_v = fixed_img_v.cuda()\n",
        "                fixed_g_v = fixed_g_v.cuda()\n",
        "        if use_cuda:\n",
        "            img_data_v = img_data_v.cuda()\n",
        "            img_age_v = img_age_v.cuda()\n",
        "            img_gender_v = img_gender_v.cuda()\n",
        "\n",
        "        # make one hot encoding version of label\n",
        "        batchSize = img_data_v.size(0)\n",
        "        age_ohe = one_hot(img_age,batchSize,n_l,use_cuda)\n",
        "\n",
        "        # prior distribution z_star, real_label, fake_label\n",
        "        z_star = Variable(torch.FloatTensor(batchSize*n_z).uniform_(-1,1)).view(batchSize,n_z)\n",
        "        real_label = Variable(torch.ones(batchSize).fill_(1)).view(-1,1)\n",
        "        fake_label = Variable(torch.ones(batchSize).fill_(0)).view(-1,1)\n",
        "\n",
        "        if use_cuda:\n",
        "            z_star, real_label, fake_label = z_star.cuda(),real_label.cuda(),fake_label.cuda()\n",
        "\n",
        "\n",
        "        ## train Encoder and Generator with reconstruction loss\n",
        "        netE.zero_grad()\n",
        "        netG.zero_grad()\n",
        "\n",
        "        # EG_loss 1. L1 reconstruction loss\n",
        "        z = netE(img_data_v)\n",
        "        reconst = netG(z,age_ohe,img_gender_v)\n",
        "        EG_L1_loss = L1(reconst,img_data_v)\n",
        "\n",
        "\n",
        "        # EG_loss 2. GAN loss - image\n",
        "        z = netE(img_data_v)\n",
        "        reconst = netG(z,age_ohe,img_gender_v)\n",
        "        D_reconst,_ = netD_img(reconst,age_ohe.view(batchSize,n_l,1,1),img_gender_v.view(batchSize,1,1,1))\n",
        "        G_img_loss = BCE(D_reconst,real_label)\n",
        "\n",
        "\n",
        "\n",
        "        ## EG_loss 3. GAN loss - z\n",
        "        Dz_prior = netD_z(z_star)\n",
        "        Dz = netD_z(z)\n",
        "        Ez_loss = BCE(Dz,real_label)\n",
        "\n",
        "        ## EG_loss 4. TV loss - G\n",
        "        reconst = netG(z.detach(),age_ohe,img_gender_v)\n",
        "        G_tv_loss = TV_LOSS(reconst)\n",
        "\n",
        "        EG_loss = EG_L1_loss + 0.0001*G_img_loss + 0.01*Ez_loss + G_tv_loss\n",
        "        EG_loss.backward()\n",
        "\n",
        "        optimizerE.step()\n",
        "        optimizerG.step()\n",
        "\n",
        "\n",
        "\n",
        "        ## train netD_z with prior distribution U(-1,1)\n",
        "        netD_z.zero_grad()\n",
        "        Dz_prior = netD_z(z_star)\n",
        "        Dz = netD_z(z.detach())\n",
        "\n",
        "        Dz_loss = BCE(Dz_prior,real_label)+BCE(Dz,fake_label)\n",
        "        Dz_loss.backward()\n",
        "        optimizerD_z.step()\n",
        "\n",
        "\n",
        "\n",
        "        ## train D_img with real images\n",
        "        netD_img.zero_grad()\n",
        "        D_img,D_clf = netD_img(img_data_v,age_ohe.view(batchSize,n_l,1,1),img_gender_v.view(batchSize,1,1,1))\n",
        "        D_reconst,_ = netD_img(reconst.detach(),age_ohe.view(batchSize,n_l,1,1),img_gender_v.view(batchSize,1,1,1))\n",
        "\n",
        "        D_loss = BCE(D_img,real_label)+BCE(D_reconst,fake_label)\n",
        "        D_loss.backward()\n",
        "        optimizerD_img.step()\n",
        "\n",
        "\n",
        "\n",
        "    ## save fixed img for every 20 step\n",
        "    fixed_z = netE(fixed_img_v)\n",
        "    fixed_fake = netG(fixed_z,fixed_l_v,fixed_g_v)\n",
        "    vutils.save_image(fixed_fake.data,\n",
        "                '%s/reconst_epoch%03d.png' % (outf,epoch+1),\n",
        "                normalize=True)\n",
        "\n",
        "    ## checkpoint\n",
        "    if epoch%10==0:\n",
        "        torch.save(netE.state_dict(),\"%s/netE_%03d.pth\"%(outf,epoch+1))\n",
        "        torch.save(netG.state_dict(),\"%s/netG_%03d.pth\"%(outf,epoch+1))\n",
        "        torch.save(netD_img.state_dict(),\"%s/netD_img_%03d.pth\"%(outf,epoch+1))\n",
        "        torch.save(netD_z.state_dict(),\"%s/netD_z_%03d.pth\"%(outf,epoch+1))\n",
        "\n",
        "\n",
        "    msg1 = \"epoch:{}, step:{}\".format(epoch+1,i+1)\n",
        "    msg2 = format(\"EG_L1_loss:%f\"%(EG_L1_loss.data[0]),\"<30\")+\"|\"+format(\"G_img_loss:%f\"%(G_img_loss.data[0]),\"<30\")\n",
        "    msg5 = format(\"G_tv_loss:%f\"%(G_tv_loss.data[0]),\"<30\")+\"|\"+\"Ez_loss:%f\"%(Ez_loss.data[0])\n",
        "    msg3 = format(\"D_img:%f\"%(D_img.mean().data[0]),\"<30\")+\"|\"+format(\"D_reconst:%f\"%(D_reconst.mean().data[0]),\"<30\")\\\n",
        "    +\"|\"+format(\"D_loss:%f\"%(D_loss.data[0]),\"<30\")\n",
        "    msg4 = format(\"D_z:%f\"%(Dz.mean().data[0]),\"<30\")+\"|\"+format(\"D_z_prior:%f\"%(Dz_prior.mean().data[0]),\"<30\")\\\n",
        "    +\"|\"+format(\"Dz_loss:%f\"%(Dz_loss.data[0]),\"<30\")\n",
        "\n",
        "    print()\n",
        "    print(msg1)\n",
        "    print(msg2)\n",
        "    print(msg5)\n",
        "    print(msg3)\n",
        "    print(msg4)\n",
        "    print()\n",
        "    print(\"-\"*80)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-067e382301e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m     vutils.save_image(fixed_fake.data,\n\u001b[1;32m    179\u001b[0m                 \u001b[0;34m'%s/reconst_epoch%03d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 normalize=True)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m## checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, filename, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1923\u001b[0m             \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m             \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1925\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './result_tv_gender/reconst_epoch001.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJNvp4bIlZfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}